---
title: "Lets Play with Causal Meta-Learners"
author: Anders Hviid
date: November 18, 2024
format: 
  revealjs:
    self-contained: false
    embed-resources: false
    footer: "Causal Meta-Learner Workshop"
    #logo: logo.png
    theme: serif
    transition: slide
    echo: false
    output: true
    chalkboard: false
slide-number: true    
---

## What are we going to do today?

-   13:00-13:30 Intro: What are heterogeneous treatment effects and meta-learners?
-   13:30-14:15 Code session I
-   14:15-14:30 Break
-   14:30-15:00 Intermezzo: More on meta-learners
-   15:00-15:45 Code session II
-   15:45-16:00 Break
-   16:00-16:30 Code session II continued
-   16:30       Wrapping up



## When ATE=0.1

![](HTEs_q1.png)

::: notes
Based on concepts from "Causal quartets: Different ways to attain the same average treatment effect" by Gelman, Hullman & Kennedy (2023)
:::

## Effect Heterogeneity

![](HTEs_q2.png)

## Heterogeneity of Treatment Effects

<img src="HTEs.jpg" alt="Caption" width="500"/>

## Why Study Effect Heterogeneity?

::: {style="font-size: 28px;"}
::: fragment
-   Real-world effects vary across:
    -   Individuals
    -   Populations
    -   Situations
    -   Time
:::

::: fragment
-   Understanding this variation is crucial for:
    -   Study design
    -   Policy decisions
    -   Personalized interventions
    -   Generalization beyond study sample
:::
:::

## Individual Treatment Effect (ITE)

<br> Formal Definition: $$
\text{ITE}_i = Y_i(1) - Y_i(0)
$$ where: - $Y_i(1)$ potential outcome under T=1 for individual $i$ - $Y_i(0)$ potential outcome under T=0 for individual $i$ <br>

::: fragment
::: callout-tip
## The Fundamental Problem of Causal Inference:

We can never observe both $Y_i(1)$ and $Y_i(0)$ for the same individual
:::
:::

## Average Treatment Effect (ATE)

<br>

Formal Definition:

$$
\text{ATE} = E[Y(1) - Y(0)] = E[Y(1)] - E(Y(0))
$$ where:

\- $Y(1)$ potential outcome under treatment

\- $Y(0)$ potential outcome under control

\- $E[Y(1)]$ Average outcome if all treated

\- $E[Y(0)]$ Average outcome if all control

## Conditional Average Treatment Effect (CATE)

Formal Definition: $$
\text{CATE}(x) = E[Y(1) | X=x] - E[Y(0) | X = x]
$$ where:

\- $X = x$ represents specific covariate values

\- $E[Y(1) | X = x]$ Average outcome if all treated in subgroup

\- $E[Y(0) | X = x]$ Average outcome if all control in subgroup <br>


## Case Study

<br>

-   Objective: Is the association between quitting smoking and mortality heterogeneous?

-   Data: 1,629 cigarette smokers who were interviewed in 1971 and 1982 and followed up until 1992.

-   Methods: Estimate heterogeneous treatment effects using causal meta-learners

## NHEFS data

```{r}
#| label: load-packages
#| output: false
library(tidyverse)
library(causaldata)
library(tableone)
library(gt)
```

```{r}
glimpse(nhefs)
```

## A Table 1

```{r}


# Load the NHEFS dataset
data("nhefs")

# Define the variables to include in the table
vars <- c("age", "sex", "race", "education", "smokeintensity", "smokeyrs", "active", "wt71", "exercise")

# Create a Table 1 stratified by quitting smoking status (qsmk)
table1 <- CreateTableOne(vars = vars, strata = "qsmk", data = nhefs, factorVars = c("sex", "race", "education", "active", "exercise"))

# Print the Table 1
print(table1, showAllLevels = TRUE)
```

## NHEFS Codebook

```{r}

nhefs_codebook %>%
  filter(variable %in% c(vars, "qsmk", "death")) %>%
  gt() %>%
  tab_header(title = "NHEFS Codebook - Selected Variables")
```

## A Table 2

<br><br>

```{r}


# Create a 2x2 table of the exposure (qsmk) and the outcome (death) with labels

table_2x2 <- table(nhefs$qsmk, nhefs$death)
dimnames(table_2x2) <- list("Quitting Smoking (qsmk)" = c("No", "Yes"), "Death" = c("No", "Yes"))

# Calculate the crude Average Treatment Effect (ATE)
n1 <- sum(nhefs$qsmk == 1)
n0 <- sum(nhefs$qsmk == 0)
y1_mean <- mean(nhefs$death[nhefs$qsmk == 1], na.rm = TRUE)
y0_mean <- mean(nhefs$death[nhefs$qsmk == 0], na.rm = TRUE)
crude_ate <- y1_mean - y0_mean

# Print the crude ATE
print(table_2x2)
print(paste("Crude ATE:", crude_ate))
```

## ATE using IPTW

```{r}
#| fig.height: 8
#| fig.width: 10
#| layout: [[1], [1]]

# Calculate IPTW weights
ps_model <- glm(qsmk ~ age + sex + race + as.factor(education) + smokeintensity + smokeyrs + as.factor(active) + wt71 + as.factor(exercise), 
                family = binomial(), data = nhefs)
nhefs$ps <- predict(ps_model, type = "response")
nhefs$iptw <- ifelse(nhefs$qsmk == 1, 1 / nhefs$ps, 1 / (1 - nhefs$ps))

# Set up plotting area for two plots
par(mfrow = c(2, 1))

# 1. Density plot of PS by treatment
plot(density(nhefs$ps[nhefs$qsmk == 1]), 
     main = "Propensity Score Distribution by Treatment",
     xlab = "Propensity Score",
     ylim = c(0, 4),
     col = "blue",
     lwd = 2)
lines(density(nhefs$ps[nhefs$qsmk == 0]), col = "red", lwd = 2)
legend("topright", 
       legend = c("Treated (Quit Smoking)", "Control (Continued Smoking)"),
       col = c("blue", "red"),
       lwd = 2)

# 2. Density plot of IPTW weights by treatment
plot(density(nhefs$iptw[nhefs$qsmk == 1]), 
     main = "IPTW Weight Distribution by Treatment",
     xlab = "IPTW Weight",
     ylim = c(0, 3),
     xlim = c(0, 15),
     col = "blue",
     lwd = 2)
lines(density(nhefs$iptw[nhefs$qsmk == 0]), col = "red", lwd = 2)
legend("topright", 
       legend = c("Treated (Quit Smoking)", "Control (Continued Smoking)"),
       col = c("blue", "red"),
       lwd = 2)

# Calculate and print ATE
treated_mean <- weighted.mean(nhefs$death[nhefs$qsmk == 1], nhefs$iptw[nhefs$qsmk == 1])
control_mean <- weighted.mean(nhefs$death[nhefs$qsmk == 0], nhefs$iptw[nhefs$qsmk == 0])
ATE <- treated_mean - control_mean
print(paste("IPTW ATE:", round(ATE, 4)))
```

## Causal Meta-Learners

<br>

-   Estimates/Predict "ITE" (CATE)
-   Uses base-learners
-   Multi-step process

::: fragment
::: callout-tip
## Base-learner: Any machine learning algorithm used as a building block in a larger modeling framework
:::
:::

## S-Learner

<figure>

<img src="SLearner.png" width="1000"/>


<figcaption>The S-learner treats the treatment indicator as just another predictor</figcaption>

</figure>

::: notes
Causal Inference in Python: Applying Causal Inference in the Tech Industry -- Matheus Facure -- 1, 2023 -- O'Reilly Media.
:::

## Implement S-Learner

```{r}
s_model <- glm(death ~ qsmk + age + sex + race + as.factor(education) + smokeintensity + smokeyrs + as.factor(active) + wt71 + as.factor(exercise), data = nhefs, family = binomial())


# Create prediction datasets
pred_data1 <- nhefs
pred_data1$qsmk <- 1  # Set everyone to treated

pred_data0 <- nhefs
pred_data0$qsmk <- 0  # Set everyone to control

# Get potential outcomes for everyone
nhefs$Y1_hat <- predict(s_model, newdata = pred_data1, type = "response")
nhefs$Y0_hat <- predict(s_model, newdata = pred_data0, type = "response")
nhefs$ITE <- nhefs$Y1_hat - nhefs$Y0_hat



```

::: columns
::: {.column width="50%"}
```{r}
# Display the first 10 rows of selected columns
nhefs %>%
  select(qsmk, death, Y1_hat, Y0_hat, ITE) %>%
  head(10) %>%
  print()

# Calculate and print the Average Treatment Effect
ate_s <- mean(nhefs$ITE)
print(paste("S-learner ATE:", round(ate_s, 4)))
```
:::

::: {.column width="50%"}
```{r}
#| fig-width: 8
#| fig-height: 6

# Plot the distribution of Individual Treatment Effects
nhefs %>%
  ggplot(aes(x = ITE)) +
  geom_density(fill = "lightblue", alpha = 0.5) +
  geom_vline(xintercept = mean(nhefs$ITE),
             color = "red", linetype = "dashed") +
  theme_minimal() +
  labs(title = "Distribution of Individual Treatment Effects",
       x = "Individual Treatment Effect",
       y = "Density") +
  theme(plot.title = element_text(size = 12))
```
:::
:::

## Time to code!

```{r}
library(countdown)
```

-   A table 1 with the covariates of your choice

-   A table 2 with crude and IPTW weighted ATEs

-   Use the S-Learner to estimate ATE and ITEs

```{r}
countdown(
  minutes = 45, style = "play",
  warn_when = 1,    # Warning color change at 5 minutes
  bottom = 0,          # Position from top
  right = 0,        # Position from right
  font_size = "2em", # Size of the timer
  color_border = "#1b9e77",        # Border color
  color_text = "#1b9e77",          # Text color
  color_running = "#1b9e77",       # Color while running
  color_warning = "#d95f02",       # Color when warn_when reached
  color_finished = "#7570b3",      # Color when finished
  margin = "0.5em",                # Margin around the timer
  padding = "0.5em"                # Padding within the timer
  )
```

## S-Learner weakness

<br>

::: callout-warning
If the treatment effect is small, some base-learners drop it!
:::

## T-Learner

<figure>

<img src="TLearner.png" width="900"/>

<figcaption>T-learner trains an ML model on T = 1 and another at T = 0; at prediction time, it uses both models to estimate the difference between treatment and control</figcaption>

</figure>

## Implement T-Learner

```{r}
# Fit separate models for treated and control groups
t1_model <- glm(death ~ age + sex + race + as.factor(education) + 
                smokeintensity + smokeyrs + as.factor(active) + 
                wt71 + as.factor(exercise),
                data = nhefs[nhefs$qsmk == 1,], 
                family = binomial())

t0_model <- glm(death ~ age + sex + race + as.factor(education) + 
                smokeintensity + smokeyrs + as.factor(active) + 
                wt71 + as.factor(exercise),
                data = nhefs[nhefs$qsmk == 0,], 
                family = binomial())

# Get potential outcomes for everyone
nhefs$Y1_hat <- predict(t1_model, newdata = nhefs, type = "response")
nhefs$Y0_hat <- predict(t0_model, newdata = nhefs, type = "response")
nhefs$ITE <- nhefs$Y1_hat - nhefs$Y0_hat
```

::: columns
::: {.column width="50%"}
```{r}
# Display the first 10 rows of selected columns
nhefs %>%
  select(qsmk, death, Y1_hat, Y0_hat, ITE) %>%
  head(10) %>%
  print()

# Calculate and print the Average Treatment Effect
ate_t <- mean(nhefs$ITE)
print(paste("T-learner ATE:", round(ate_t, 4)))
```
:::

::: {.column width="50%"}
```{r}
#| fig-width: 8
#| fig-height: 6

# Plot the distribution of Individual Treatment Effects
nhefs %>%
  ggplot(aes(x = ITE)) +
  geom_density(fill = "lightblue", alpha = 0.5) +
  geom_vline(xintercept = mean(nhefs$ITE),
             color = "red", linetype = "dashed") +
  theme_minimal() +
  labs(title = "Distribution of Individual Treatment Effects",
       x = "Individual Treatment Effect",
       y = "Density") +
  theme(plot.title = element_text(size = 12))
```
:::
:::

## T-Learner weakness

<br>

::: callout-warning
Few treated -\> poor prediction of outcome among treated!
:::

## X-Learner

![](XLearner.png)

<figcaption> X-learner trains outcome models on each treatment group to estimates treatment effects using observed and predicted outcomes, then trains models on these effects to estimate CATE weighted using PS
</figcaption>

## Implement X-Learner

```{r}
# Step 1: Fit separate models for treated and control groups (same as T-learner)
# First stage models
x1_model <- glm(death ~ age + sex + race + as.factor(education) + 
                smokeintensity + smokeyrs + as.factor(active) + 
                wt71 + as.factor(exercise),
                data = nhefs[nhefs$qsmk == 1,], 
                family = binomial())

x0_model <- glm(death ~ age + sex + race + as.factor(education) + 
                smokeintensity + smokeyrs + as.factor(active) + 
                wt71 + as.factor(exercise),
                data = nhefs[nhefs$qsmk == 0,], 
                family = binomial())

# Step 2: Compute imputed treatment effects
# For treated group
treated_idx <- nhefs$qsmk == 1
nhefs$D1[treated_idx] <- nhefs$death[treated_idx] - 
                        predict(x0_model, newdata = nhefs[treated_idx,], type = "response")

# For control group
control_idx <- nhefs$qsmk == 0
nhefs$D0[control_idx] <- predict(x1_model, newdata = nhefs[control_idx,], type = "response") - 
                        nhefs$death[control_idx]

# Step 3: Fit second stage models on the imputed treatment effects
x1_second_model <- glm(D1 ~ age + sex + race + as.factor(education) + 
                      smokeintensity + smokeyrs + as.factor(active) + 
                      wt71 + as.factor(exercise),
                      data = nhefs[treated_idx,])

x0_second_model <- glm(D0 ~ age + sex + race + as.factor(education) + 
                      smokeintensity + smokeyrs + as.factor(active) + 
                      wt71 + as.factor(exercise),
                      data = nhefs[control_idx,])

# Step 4: Get treatment effect predictions
tau1 <- predict(x1_second_model, newdata = nhefs)
tau0 <- predict(x0_second_model, newdata = nhefs)

# Step 5: Calculate propensity scores for weighting
ps_model <- glm(qsmk ~ age + sex + race + as.factor(education) + 
                smokeintensity + smokeyrs + as.factor(active) + 
                wt71 + as.factor(exercise),
                data = nhefs, family = binomial())
nhefs$ps <- predict(ps_model, type = "response")

# Step 6: Compute final treatment effects using propensity score weighting
nhefs$ITE <- with(nhefs, ps * tau1 + (1 - ps) * tau0)
```

::: columns
::: {.column width="50%"}
```{r}
# Display the first 10 rows of selected columns
nhefs %>%
  select(qsmk, death, ps, ITE) %>%
  head(10) %>%
  print()

# Calculate and print the Average Treatment Effect
ate_x <- mean(nhefs$ITE)
print(paste("X-learner ATE:", round(ate_x, 4)))
```
:::

::: {.column width="50%"}
```{r}
#| fig-width: 8
#| fig-height: 6

# Plot the distribution of Individual Treatment Effects
nhefs %>%
  ggplot(aes(x = ITE)) +
  geom_density(fill = "lightblue", alpha = 0.5) +
  geom_vline(xintercept = mean(nhefs$ITE),
             color = "red", linetype = "dashed") +
  theme_minimal() +
  labs(title = "Distribution of Individual Treatment Effects",
       x = "Individual Treatment Effect",
       y = "Density") +
  theme(plot.title = element_text(size = 12))
```
:::
:::

## Bootstrap 95% CIs {.smaller}

```{r}
#| warning: false
#| message: false

library(tidyverse)
library(boot)

# Function to compute X-learner estimates for a bootstrap sample
x_learner_boot <- function(data, indices) {
  # Get bootstrap sample
  boot_data <- data[indices,]
  
  # First stage models
  x1_model <- glm(death ~ age + sex + race + as.factor(education) + 
                  smokeintensity + smokeyrs + as.factor(active) + 
                  wt71 + as.factor(exercise),
                  data = boot_data[boot_data$qsmk == 1,], 
                  family = binomial())
  
  x0_model <- glm(death ~ age + sex + race + as.factor(education) + 
                  smokeintensity + smokeyrs + as.factor(active) + 
                  wt71 + as.factor(exercise),
                  data = boot_data[boot_data$qsmk == 0,], 
                  family = binomial())
  
  # Compute imputed treatment effects
  treated_idx <- boot_data$qsmk == 1
  boot_data$D1[treated_idx] <- boot_data$death[treated_idx] - 
                              predict(x0_model, newdata = boot_data[treated_idx,], 
                                    type = "response")
  
  control_idx <- boot_data$qsmk == 0
  boot_data$D0[control_idx] <- predict(x1_model, newdata = boot_data[control_idx,], 
                                     type = "response") - 
                              boot_data$death[control_idx]
  
  # Second stage models
  x1_second_model <- glm(D1 ~ age + sex + race + as.factor(education) + 
                        smokeintensity + smokeyrs + as.factor(active) + 
                        wt71 + as.factor(exercise),
                        data = boot_data[treated_idx,])
  
  x0_second_model <- glm(D0 ~ age + sex + race + as.factor(education) + 
                        smokeintensity + smokeyrs + as.factor(active) + 
                        wt71 + as.factor(exercise),
                        data = boot_data[control_idx,])
  
  # Get predictions
  tau1 <- predict(x1_second_model, newdata = data)  
  tau0 <- predict(x0_second_model, newdata = data)
  
  # Propensity scores
  ps_model <- glm(qsmk ~ age + sex + race + as.factor(education) + 
                  smokeintensity + smokeyrs + as.factor(active) + 
                  wt71 + as.factor(exercise),
                  data = boot_data, family = binomial())
  ps <- predict(ps_model, newdata = data, type = "response")
  
  # Final ITE estimates
  ite <- ps * tau1 + (1 - ps) * tau0
  
  # Return both ATE and ITEs
  return(c(mean(ite), ite))
}
```

```{r}
#| warning: false
#| message: false

# Run bootstrap
set.seed(123)
n_boot <- 1000
boot_results <- boot(nhefs, x_learner_boot, R = n_boot)

# Get ATE confidence interval
ate_ci <- boot.ci(boot_results, type = "perc", index = 1)

# Get ITE confidence intervals
ite_cis <- t(sapply(2:(nrow(nhefs) + 1), function(i) {
  ci <- boot.ci(boot_results, type = "perc", index = i)$percent[4:5]
  return(ci)
}))

# Add CIs to dataset
nhefs$ITE_lower <- ite_cis[,1]
nhefs$ITE_upper <- ite_cis[,2]

# Print ATE with CI
cat("Average Treatment Effect:", round(boot_results$t0[1], 4), "\n")
cat("95% CI: [", round(ate_ci$percent[4], 4), ",", 
    round(ate_ci$percent[5], 4), "]\n")
```

## Bootstrap Visualization {.smaller}

```{r}
#| warning: false
#| message: false
#| fig-width: 10
#| fig-height: 6

# Add significance indicator to the dataset
nhefs <- nhefs %>%
  mutate(
    significant = !(ITE_lower <= 0 & ITE_upper >= 0),  # True if CI doesn't cross zero
    effect_type = case_when(
      significant & ITE > 0 ~ "Significant Positive",
      significant & ITE < 0 ~ "Significant Negative",
      TRUE ~ "Not Significant"
    )
  ) %>%
  arrange(ITE) %>%
  mutate(rank = row_number())

# Create the improved plot
ggplot(nhefs, aes(x = rank, y = ITE)) +
  # Add confidence interval ribbon
  geom_ribbon(aes(ymin = ITE_lower, ymax = ITE_upper),
              alpha = 0.15, fill = "grey50") +
  # Add zero reference line
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", alpha = 0.5) +
  # Add individual effects with color
  geom_point(aes(color = effect_type), size = 1) +
  # Use a better color scheme
  scale_color_manual(values = c(
    "Not Significant" = "grey50",
    "Significant Negative" = "#D95F02",
    "Significant Positive" = "#1B9E77"
  )) +
  # Improve theme
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(size = 12),
    legend.title = element_text(size = 10),
    legend.text = element_text(size = 9)
  ) +
  # Better labels
  labs(
    title = "Ranked Individual Treatment Effects with 95% Bootstrap CIs",
    x = "Rank",
    y = "Individual Treatment Effect",
    color = "Effect Type"
  ) +
  # Set axis limits with some padding
  scale_y_continuous(limits = c(
    min(nhefs$ITE_lower, na.rm = TRUE) - 0.05,
    max(nhefs$ITE_upper, na.rm = TRUE) + 0.05
  ))

# Print summary of significant effects
sig_pos <- nhefs %>% filter(effect_type == "Significant Positive") %>% nrow()
sig_neg <- nhefs %>% filter(effect_type == "Significant Negative") %>% nrow()
total <- nrow(nhefs)

cat(sprintf("\nOut of %d individuals:", total))
cat(sprintf("\n- %d (%.1f%%) have significant positive effects", 
            sig_pos, 100 * sig_pos/total))
cat(sprintf("\n- %d (%.1f%%) have significant negative effects", 
            sig_neg, 100 * sig_neg/total))
```

::: {style="font-size: 0.6em;"}
Note: Significant effects (orange) have 95% bootstrap CIs that do not include zero
:::

## ML base learners

-   Penalised regression (parametric)

-   Tree-based methods (non-parametric)

-   Neural networks (non-parametric)

-   Support vector machines (non-parametric)

## Overfitting

![](Overfitting.png) [^1]

[^1]: Ref: https://carpentries-incubator.github.io/ml4bio-workshop/04-trees-overfitting/index.html

## Which Causal Meta-Learner to choose?

::: {style="font-size: 75%;"}
| Scenario             | S-Learner    | T-Learner    | X-Learner    |
|----------------------|--------------|--------------|--------------|
| **Sample Size**      |              |              |              |
| Large Sample         | OK           | OK           | OK           |
| Small Sample         | OK           | May Struggle | May Struggle |
| **Treatment Effect** |              |              |              |
| Large Effects        | OK           | OK           | OK           |
| Small Effects        | May Struggle | OK           | OK           |
| **Data Balance**     |              |              |              |
| Balanced Data        | OK           | OK           | OK           |
| Imbalanced Data      | OK           | May Struggle | OK           | 
:::

## Time to code!

```{r}
library(countdown)
```

-   Use the T- or X-Learner to estimate ATE and ITEs with 95% CIs

-   Choose your own base-learner(s)

-   Consider how to avoid overfitting

-   Identify factors (e.g. is age?) associated with effect heterogeneity

```{r}
countdown(
  minutes = 75, style = "play",
  warn_when = 1,    # Warning color change at 5 minutes
  bottom = 0,          # Position from top
  right = 0,        # Position from right
  font_size = "2em", # Size of the timer
  color_border = "#1b9e77",        # Border color
  color_text = "#1b9e77",          # Text color
  color_running = "#1b9e77",       # Color while running
  color_warning = "#d95f02",       # Color when warn_when reached
  color_finished = "#7570b3",      # Color when finished
  margin = "0.5em",                # Margin around the timer
  padding = "0.5em"                # Padding within the timer
  )
```

## What have we learned?
