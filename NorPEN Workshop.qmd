---
title: "Lets Play with Causal Meta-Learners"
author: Anders Hviid
date: November 18, 2024
format: 
  revealjs:
    self-contained: false
    embed-resources: false
    footer: "Causal Meta-Learner Workshop"
    #logo: logo.png
    theme: serif
    transition: slide
    echo: false
    output: true
    chalkboard: false
slide-number: true    
---

## What are we going to do today?

-   Study Q: Is the association between quitting smoking and mortality heterogeneous?

-   Data: 1,629 cigarette smokers who were interviewed in 1971 and 1982 and followed up until 1992.

-   Methods: Estimate heterogeneous treatment effects using causal meta-learners

## A Simple Example

<br> <br>

|             | Recovered | Not Recovered |
|-------------|-----------|---------------|
| **Treated** | 1500      | 1500          |
| **Control** | 1200      | 1800          |

<br>

Average Treatment Effect = 0.1 <br>

This does NOT imply lack of individual treatment effects!

## Heterogeneity of Treatment Effects

<img src="HTEs.jpg" alt="Caption" width="500"/>

## Individual Treatment Effect (ITE)

<br> Formal Definition: $$
\text{ITE}_i = Y_i(1) - Y_i(0)
$$ where: - $Y_i(1)$ potential outcome under T=1 for individual $i$ - $Y_i(0)$ potential outcome under T=0 for individual $i$ <br>

::: callout-tip
## The Fundamental Problem of Causal Inference:

We can never observe both $Y_i(1)$ and $Y_i(0)$ for the same individual
:::

## Average Treatment Effect (ATE)

<br>

Formal Definition:

$$
\text{ATE} = E[Y(1) - Y(0)] = E[Y(1)] - E(Y(0))
$$ where:

\- $Y(1)$ potential outcome under treatment

\- $Y(0)$ potential outcome under control

\- $E[Y(1)]$ Average outcome if all treated

\- $E[Y(0)]$ Average outcome if all control

## Conditional Average Treatment Effect (CATE)

Formal Definition: $$
\text{CATE}(x) = E[Y(1) | X=x] - E[Y(0) | X = x]
$$ where:

\- $X = x$ represents specific covariate values

\- $E[Y(1) | X = x]$ Average outcome if all treated in subgroup

\- $E[Y(0) | X = x]$ Average outcome if all control in subgroup <br>

## NHEFS data

```{r}
#| label: load-packages
#| output: false
library(tidyverse)
library(causaldata)
library(tableone)
library(gt)
```

```{r}
glimpse(nhefs)
```

## A Table 1

```{r}


# Load the NHEFS dataset
data("nhefs")

# Define the variables to include in the table
vars <- c("age", "sex", "race", "education", "smokeintensity", "smokeyrs", "active", "wt71", "exercise")

# Create a Table 1 stratified by quitting smoking status (qsmk)
table1 <- CreateTableOne(vars = vars, strata = "qsmk", data = nhefs, factorVars = c("sex", "race", "education", "active", "exercise"))

# Print the Table 1
print(table1, showAllLevels = TRUE)
```

## NHEFS Codebook

```{r}

nhefs_codebook %>%
  filter(variable %in% c(vars, "qsmk", "death")) %>%
  gt() %>%
  tab_header(title = "NHEFS Codebook - Selected Variables")
```

## A Table 2

<br><br>

```{r}


# Create a 2x2 table of the exposure (qsmk) and the outcome (death) with labels

table_2x2 <- table(nhefs$qsmk, nhefs$death)
dimnames(table_2x2) <- list("Quitting Smoking (qsmk)" = c("No", "Yes"), "Death" = c("No", "Yes"))

# Calculate the crude Average Treatment Effect (ATE)
n1 <- sum(nhefs$qsmk == 1)
n0 <- sum(nhefs$qsmk == 0)
y1_mean <- mean(nhefs$death[nhefs$qsmk == 1], na.rm = TRUE)
y0_mean <- mean(nhefs$death[nhefs$qsmk == 0], na.rm = TRUE)
crude_ate <- y1_mean - y0_mean

# Print the crude ATE
print(table_2x2)
print(paste("Crude ATE:", crude_ate))
```

## ATE using IPTW

```{r}
#| fig.height: 8
#| fig.width: 10
#| layout: [[1], [1]]

# Calculate IPTW weights
ps_model <- glm(qsmk ~ age + sex + race + as.factor(education) + smokeintensity + smokeyrs + as.factor(active) + wt71 + as.factor(exercise), 
                family = binomial(), data = nhefs)
nhefs$ps <- predict(ps_model, type = "response")
nhefs$iptw <- ifelse(nhefs$qsmk == 1, 1 / nhefs$ps, 1 / (1 - nhefs$ps))

# Set up plotting area for two plots
par(mfrow = c(2, 1))

# 1. Density plot of PS by treatment
plot(density(nhefs$ps[nhefs$qsmk == 1]), 
     main = "Propensity Score Distribution by Treatment",
     xlab = "Propensity Score",
     ylim = c(0, 4),
     col = "blue",
     lwd = 2)
lines(density(nhefs$ps[nhefs$qsmk == 0]), col = "red", lwd = 2)
legend("topright", 
       legend = c("Treated (Quit Smoking)", "Control (Continued Smoking)"),
       col = c("blue", "red"),
       lwd = 2)

# 2. Density plot of IPTW weights by treatment
plot(density(nhefs$iptw[nhefs$qsmk == 1]), 
     main = "IPTW Weight Distribution by Treatment",
     xlab = "IPTW Weight",
     ylim = c(0, 3),
     xlim = c(0, 15),
     col = "blue",
     lwd = 2)
lines(density(nhefs$iptw[nhefs$qsmk == 0]), col = "red", lwd = 2)
legend("topright", 
       legend = c("Treated (Quit Smoking)", "Control (Continued Smoking)"),
       col = c("blue", "red"),
       lwd = 2)

# Calculate and print ATE
treated_mean <- weighted.mean(nhefs$death[nhefs$qsmk == 1], nhefs$iptw[nhefs$qsmk == 1])
control_mean <- weighted.mean(nhefs$death[nhefs$qsmk == 0], nhefs$iptw[nhefs$qsmk == 0])
ATE <- treated_mean - control_mean
print(paste("IPTW ATE:", round(ATE, 4)))
```

## Causal Meta-Learners

<br>

-   Uses base-learners
-   Multi-step process

::: callout-tip
## Base-learner: Any machine learning algorithm used as a building block in a larger modeling framework
:::

## S-Learner

<figure>

<img src="SLearner.png" width="1000"/>

<figcaption>The S-learner treats the treatment indicator as just another predictor</figcaption>

</figure>

## Implement S-Learner

```{r}
s_model <- glm(death ~ qsmk + age + sex + race + as.factor(education) + smokeintensity + smokeyrs + as.factor(active) + wt71 + as.factor(exercise), data = nhefs, family = binomial())


# Create prediction datasets
pred_data1 <- nhefs
pred_data1$qsmk <- 1  # Set everyone to treated

pred_data0 <- nhefs
pred_data0$qsmk <- 0  # Set everyone to control

# Get potential outcomes for everyone
nhefs$Y1_hat <- predict(s_model, newdata = pred_data1, type = "response")
nhefs$Y0_hat <- predict(s_model, newdata = pred_data0, type = "response")
nhefs$ITE <- nhefs$Y1_hat - nhefs$Y0_hat



```

::: columns
::: {.column width="50%"}
```{r}
# Display the first 10 rows of selected columns
nhefs %>%
  select(qsmk, death, Y1_hat, Y0_hat, ITE) %>%
  head(10) %>%
  print()

# Calculate and print the Average Treatment Effect
ate_s <- mean(nhefs$ITE)
print(paste("S-learner ATE:", round(ate_s, 4)))
```
:::

::: {.column width="50%"}
```{r}
#| fig-width: 8
#| fig-height: 6

# Plot the distribution of Individual Treatment Effects
nhefs %>%
  ggplot(aes(x = ITE)) +
  geom_density(fill = "lightblue", alpha = 0.5) +
  geom_vline(xintercept = mean(nhefs$ITE),
             color = "red", linetype = "dashed") +
  theme_minimal() +
  labs(title = "Distribution of Individual Treatment Effects",
       x = "Individual Treatment Effect",
       y = "Density") +
  theme(plot.title = element_text(size = 12))
```
:::
:::

## S-Learner weakness

<br>

::: callout-warning
If the treatment effect is small, some base-learners drop it!
:::

## T-Learner

<figure>

<img src="TLearner.png" width="900"/>

<figcaption>T-learner trains an ML model on T = 1 and another at T = 0; at prediction time, it uses both models to estimate the difference between treatment and control</figcaption>

</figure>

## Implement T-Learner

## X-Learner

## Implement X-Learner

## Bootstrap 95% CIs

## ML base learners

-   Penalised regression

-   Tree-based methods

-   Neural networks

## Overfitting

## Implement T-Learner with XGBoost

## CATE presentations

-   histogram

-   ranked ITEs with 95% CIs colored in

-   partial dependence plots

## What have we learned?
